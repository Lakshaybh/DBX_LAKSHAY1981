{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e0f2a6-e7c6-4780-9970-416df24d5f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"clinisight_analytics.default.cleaned_healthcare_data_unique\"\n",
    "\n",
    "# Read table\n",
    "df = spark.table(table_name)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Table path:\", table_name)\n",
    "print(\"Number of rows (approx):\", df.count())\n",
    "display(df.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2a8a12f-a3ca-4108-92f2-2745c4c33ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this step, we will undertake essential data preparation tasks to ensure the dataset is suitable for predictive modeling. Specifically, we will:\n",
    "\n",
    "- Select a subset of relevant columns that are most informative for the prediction task, thereby reducing dimensionality and focusing on features that contribute meaningfully to model performance.\n",
    "- Standardize data types by converting numerical columns to appropriate numeric formats, which facilitates accurate computations and ensures compatibility with machine learning algorithms.\n",
    "- Identify and remove any rows containing missing or null values to maintain data integrity and prevent potential issues during model training and evaluation.\n",
    "\n",
    "These actions are critical for enhancing data quality, improving model reliability, and streamlining the subsequent analytical workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b067306-a7d0-4ba4-ad40-22b22bdec861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "\n",
    "df_ml = df.select(\n",
    "    \"Patient_ID\",\n",
    "    \"Age\",\n",
    "    \"Gender\",\n",
    "    \"Medical Condition\",\n",
    "    \"Hospital\",\n",
    "    \"Length of Stay\",\n",
    "    \"Billing Amount ($)\"\n",
    ")\n",
    "\n",
    "# Clean and cast numeric columns\n",
    "df_ml = df_ml.withColumn(\n",
    "    \"Age\",\n",
    "    F.col(\"Age\").cast(IntegerType())\n",
    ").withColumn(\n",
    "    \"Length_of_Stay\",\n",
    "    F.col(\"Length of Stay\").cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"BillingAmount\",\n",
    "    F.regexp_replace(\n",
    "        F.col(\"Billing Amount ($)\"),\n",
    "        \"[$,]\",\n",
    "        \"\"\n",
    "    ).cast(DoubleType())\n",
    ")\n",
    "\n",
    "# Drop missing or invalid rows\n",
    "df_ml = df_ml.na.drop(\n",
    "    subset=[\n",
    "        \"Age\",\n",
    "        \"Gender\",\n",
    "        \"Medical Condition\",\n",
    "        \"Hospital\",\n",
    "        \"Length_of_Stay\",\n",
    "        \"BillingAmount\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Row count after cleaning:\", df_ml.count())\n",
    "display(df_ml.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0df53d0e-1af8-4d99-91e1-1677ae72d63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train Your Prediction Model: Predicting Patient Length of Stay\n",
    "\n",
    "In this step, we will build and train a machine learning model to predict the length of stay for patients based on relevant features in our dataset. This process involves:\n",
    "\n",
    "- Selecting informative features that influence patient length of stay, such as demographics, admission details, and clinical variables.\n",
    "- Splitting the data into training and test sets to evaluate model performance.\n",
    "- Choosing an appropriate regression algorithm for predicting continuous outcomes.\n",
    "- Training the model on historical data and validating its accuracy using standard metrics.\n",
    "- Interpreting the results to understand which factors most impact patient length of stay.\n",
    "\n",
    "By the end of this step, you will have a predictive model that can estimate how long a patient is likely to remain in care, supporting resource planning and operational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf776449-abf4-4a21-82d2-2e8b225bf8cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Build and train a simple ML model to predict Length of Stay\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1️⃣ Define categorical columns\n",
    "categorical_cols = [\"Gender\", \"Medical Condition\", \"Hospital\"]\n",
    "\n",
    "# Index + one-hot encode categorical features\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_Index\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "encoder = OneHotEncoder(inputCols=[f\"{c}_Index\" for c in categorical_cols],\n",
    "                        outputCols=[f\"{c}_Vec\" for c in categorical_cols])\n",
    "\n",
    "# 2️⃣ Define numeric columns and final feature vector\n",
    "numeric_cols = [\"Age\", \"BillingAmount\"]\n",
    "assembler_inputs = [f\"{c}_Vec\" for c in categorical_cols] + numeric_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# 3️⃣ Define the regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Length_of_Stay\")\n",
    "\n",
    "# 4️⃣ Create a pipeline for transformations + model\n",
    "pipeline = Pipeline(stages=indexers + [encoder, assembler, lr])\n",
    "\n",
    "# 5️⃣ Split data into training and testing sets\n",
    "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 6️⃣ Fit (train) the model\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# 7️⃣ Make predictions on test data\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Show some predicted vs actual values\n",
    "display(predictions.select(\"Patient_ID\", \"Length_of_Stay\", \"prediction\").limit(10))\n",
    "\n",
    "\n",
    "# Step 6: Evaluate model performance\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Length_of_Stay\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Length_of_Stay\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"RMSE (error): {rmse}\")\n",
    "print(f\"R² (goodness of fit): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8de5ccae-5584-495d-b7c3-1a100cdb0996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now that your predictive model is operational, the next step is to persist your predictions for seamless integration and visualization within your Databricks dashboard. Saving these results enables efficient analysis, facilitates data-driven decision making, and enhances collaboration across teams. By storing your predictions in a structured format, you ensure they are readily accessible for reporting, monitoring, and further exploration in your analytics workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc104c62-6340-449b-8770-8dfd50320571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0738f6a-acdd-402a-98bb-4d97b20eea7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rename \"Medical Condition\" to \"Medical_Condition\" to avoid invalid characters\n",
    "predictions_table = predictions.select(\n",
    "    \"Patient_ID\",\n",
    "    \"Age\",\n",
    "    \"Gender\",\n",
    "    F.col(\"Medical Condition\").alias(\"Medical_Condition\"),\n",
    "    \"Hospital\",\n",
    "    F.round(\"Length_of_Stay\", 2).alias(\"Actual_Stay\"),\n",
    "    F.round(\"prediction\", 2).alias(\"Predicted_Stay\")\n",
    ")\n",
    "\n",
    "# Save as a managed Delta table (overwrites safely)\n",
    "output_table = \"clinisight_analytics.default.ai_length_of_stay_predictions\"\n",
    "predictions_table.write.mode(\"overwrite\").saveAsTable(output_table)\n",
    "\n",
    "print(f\"✅ Predictions saved successfully to: {output_table}\")\n",
    "display(predictions_table.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25f39409-8cf9-4b8b-9ceb-11f555666160",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Clinisight_AI_Predictions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
